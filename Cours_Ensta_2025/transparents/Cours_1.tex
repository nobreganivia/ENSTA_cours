\documentclass[compress,10pt,aspectratio=169]{beamer}
\usetheme[customnumbering]{onera}

\usepackage{amsmath,amsfonts,graphicx}
\usepackage{pifont}
\usepackage{etoolbox}
\usepackage{multicol}
\usepackage{anyfontsize}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{colortbl}
\usepackage{eurosym}
\usepackage{mdframed}
%\setlength{\columnseprule}{1pt}
%\def\columnseprulecolor{\color{blue}}
\usepackage{minted} % syntax coloring. 
\setminted{encoding=utf-8, autogobble}
\usemintedstyle{xcode}
\AtBeginEnvironment{minted}{\fontsize{8}{8}\selectfont}

%\usepackage{dsfont}
\usepackage{ifdraft}
\ifdraft{
  \usepackage{fancyvrb}
  \DefineVerbatimEnvironment{cppcode}{Verbatim}{}
}{
\newminted{cpp}{}
}
\usepackage{hyperref}
\usetikzlibrary{shadows, arrows, decorations.pathmorphing, fadings, shapes.arrows, positioning, calc, shapes, fit, matrix,math}

\definecolor{lightblue}{RGB}{0,200,255} 
\definecolor{paper}{RGB}{255,247,197}
\definecolor{ocre}{RGB}{243,102,25} % Define the orange color used for highlighting throughout the book
\definecolor{BurntOrange}{RGB}{238,154,0}
\definecolor{darkorange}{RGB}{119, 77, 0}
\definecolor{OliveGreen}{RGB}{188,238,104}
\definecolor{DarkGreen}{RGB}{0,128,0}
\definecolor{BrickRed}{RGB}{238,44,44}
\definecolor{Tan}{RGB}{210,180,140}
\definecolor{Aquamarine}{RGB}{127,255,212}
\definecolor{NavyBlue}{RGB}{0,64,128}
\definecolor{DarkYellow}{RGB}{192,192,0}
\definecolor{Yellow}{RGB}{255,255,0}

\title[Parallel programming\hspace{2em}]{Programming parallel computers}
\subtitle{Introduction}
\author[X. JUVIGNY]{Xavier JUVIGNY, AKOU, DAAA, ONERA\\ \href{mailto:xavier.juvigny@onera.fr}{\texttt{xavier.juvigny@onera.fr}} }
\date[01/14/2025]{Course Parallel Programming\\- January 14th 2025 -}
\institute{\inst{1}ONERA,\inst{2}DAAA}

\AtBeginSection[]{
  \begin{frame}{Overview}
  \small \tableofcontents[currentsection, hideallsubsections]
  \end{frame} 
}

\begin{document}

\MakeTitlePage

\begin{frame}
\frametitle{Table of contents}
\tableofcontents[hideallsubsections]
\end{frame}

\section{Motivations}

\begin{frame}[fragile]{Parallel architecture}
    \small
    \begin{block}{The main story}
        \begin{itemize}
            \item Processors with multiple computing cores for faster computation
            \item Simultaneously using many cores for a unique application
            \item Performance benchmark in scientific computing is given by the number of FLoating Operations Per Second (FLOPS)
        \end{itemize}
    \end{block}

    \begin{exampleblock}{Hardware implementation}
        \begin{itemize}
            \item Many computing cores sharing the same main memory inside a computer
            \item Using many computers linked with a fast, specialized Ethernet connection
            \item Mixing both technologies mentioned above.
        \end{itemize}
    \end{exampleblock}
\end{frame}

\subsection{Motivations}

\begin{frame}[fragile]{Interests of parallel architecture ?}
    \small
    \begin{itemize}
        \item \textbf{\textcolor{NavyBlue}{Gordon Moore's "Law"}} : In 1965, Gordon Moore (one of Intel's founder) observed that the 
              number of transistors for each generation of processors doubled in eighteen months, thereby doubling the computing power.
        \item In fact, \alert{it isn't a law}, but it was used by processor builders as a roadmap until 2000 years to increase the frequency
              of computing cores.
        \item \textbf{\textcolor{red}{Limitations of Gordon Moore's Law}} : The miniaturisation of transistors and the increase in their
              frequencies lead to higher heat production inside the processor. Moreover, miniaturisation is now at the molecular scale, and one must
              consider quantum effects (such as tunnelling) when manufacturing a processor.
        \item Nowadays, \textbf{\textcolor{DarkGreen}{Moore's law is still verified}}, not by doubling the number of transistors 
              inside a computing core, but rather by increasing the number of computing cores inside a processor or computer.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{Parallel computing example (1)}
    \framesubtitle{Control command}
    \small
    \begin{multicols}{2}
    \begin{figure}[h]      
    \includegraphics[width=\linewidth]{../images/ControleCommande.png}
    \caption{Car's control command}
    \end{figure}
    \begin{itemize}
        \item Many tiny computers are specialized for specific tasks : ABS, motor optimization, lighting, air conditioning, wheel pressure optimization, 
              fuel/air mixture, battery optimization, and so on.
        \item Computations must be completed within specific time constraints.
        \item Many parameters are interdependent (external air temperature, wheel pressure, optimal speed and oil consumption).
    \end{itemize}
    \end{multicols}
\end{frame}

\begin{frame}[fragile]{Parallel computing example (1)}
    \framesubtitle{Control command (continuation)}
    \small
    \begin{multicols}{2}
        \begin{figure}[h]      
            \includegraphics[width=\linewidth]{../images/NuclearPlantSimpson.png}
            \caption{None Control Command of a reactor}
        \end{figure}
    \begin{itemize}
        \item Another control command : managing nuclear power reactors
        \item High real-time constraint algorithms
        \item Many complex computations
        \item One computing core isn't sufficient to meet tight real-time constraints.
        \item \textcolor{blue}{\bf Solution} : Concurrent execution of interdependent tasks on multiple computing cores.
    \end{itemize}
\end{multicols}
\end{frame}

\begin{frame}[fragile]{Parallel computation example (2)}
    \framesubtitle{Physical Simulation}
    \small
    \begin{multicols}{2}
        \begin{figure}[h]
            \includegraphics[width=.6\linewidth]{../images/SlatWingTurb1.jpg}
            \caption{Turbulent noise generated by a plane's slate wing}
        \end{figure}

        \begin{itemize}
            \item Turbulence : very small phenomena (millimeter scale). Requires     a mesh with lots of tiny triangles.
            \item Typically, the mesh must contain five to ten billions vertices with five unknown variables for each vertex.
            \item Minimum memory requirement : 7 TB (terabytes).
            \item Sequential computation time : 23 days to simulate $10^{-2}$ seconds.
        \end{itemize}
    \end{multicols}
\end{frame}

\begin{frame}[fragile]{Parallel computation example (3)}
    \framesubtitle{Artificial intelligence}
    \small
    \begin{columns}
        \begin{column}{.5\textwidth}
            \begin{figure}[h]
                \includegraphics[width=\linewidth]{../images/HAL.png}
                \caption{A very famous artificial intelligence (HAL)}
            \end{figure}        
        \end{column}
        \begin{column}{.5\textwidth}
            \begin{itemize}
                \item Deep learning is used in AI for tasks such as categorizing pictures, automatic translations, detecting cancerous cells, and autonomous vehicles.
                \item In a sequential process, it requires more than a year to learn
                \item With GPGPU, it takes about a few hours or days
                \item \textcolor{blue}{March 2016} : AlphaGo wins against the world GO human champion (supervised learning).
                \item \textcolor{DarkGreen}{October 2017}: AlphaGo zero wins against alphaGo with a score of 100 games to zero (deep learning).
            \end{itemize}            
        \end{column}
    \end{columns}
%  \begin{multicols}{2}
%  \end{multicols}
\end{frame}

\begin{frame}[fragile]{Parallel computation (4)}
  \framesubtitle{Picture treatment}
  \scriptsize
  \begin{figure}[h]
  \includegraphics[width=\linewidth]{../images/fluxvideo.png}
  \caption{Real-time constraint treatment of a video with 30 frames/s (resolution 1920 $\times$ 1080 pixels)}
  \end{figure}
  \begin{itemize}
  \item Required for optical sensors for navigation of autonomous vehicles, for super-resolution pictures derived from low-resolution video, and more.
  \item Involves a significant amount of computations (PDE equations to solve).
  \item Requires the use of GPGPU and parallel algorithms to meet real-time constraints.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Top 10 of supercomputers (June 2020)}
  \small
  \begin{center}
  \begin{tabular}{|>{\columncolor{cyan!25}\bfseries}c|c|c|c|>{\columncolor{yellow!50}}c|c|}\hline
    \rowcolor{green!25} Name & Core & Perf. (TFlops/s) & Constructor      & Country  & Power (kW) \\ \hline\hline
    Fugaku            & 7 299 072 & 415 530 & Fujitsu    & Japan & 28 335 \\ \hline
    Summit            & 2 414 592 & 148 600 & IBM        & USA   & 10 096 \\ \hline
    Sierra            & 1 572 480 & 94  640 & IBM/NVidia & USA   &  7 438 \\ \hline
    Sunway TaihuLight & 10 649 600 & 93 014 & NRCPC      & China & 15 371 \\ \hline
    Tianhe-2A         &  4 981 760 & 61 444 & NUDT       & China & 18 482 \\ \hline
    HPC5              &    669 760 & 35 450 & Dell EMC   & Italy &  2 252 \\ \hline
    Selene            &    277 760 & 27 580 & Nvidia     & USA   &  1 344 \\ \hline
    Frontera          &    448 448 & 23 516 & Dell EMC   & USA   &  ?     \\ \hline
    Marconi-100       &    347 776 & 21 640 & IBM        & Italy &  1 476 \\ \hline
    Frontier          &    591 872 &  1 102 & HPE        & USA   & 21 000 \\ \hline
  \end{tabular}
  \end{center}
  \textbf{\textcolor{blue}{Remark}} : Nowadays, we look for Flops/Watt performances
\end{frame}

\begin{frame}[fragile]{Top 10 of supercomputers (November 2022)}
    \small
    \begin{center}
    \begin{tabular}{|>{\columncolor{cyan!25}\bfseries}c|c|c|c|>{\columncolor{yellow!50}}c|c|}\hline
      \rowcolor{green!25} Name & Core & Perf. (TFlops/s) & Constructor & Country & Power (kW) \\ \hline\hline
      Frontier          &  8 730 112 & 1 102 000 & HPE       & USA     & 21 100 \\ \hline
      Fugaku            &  7 630 848 &  442 010 & Fujitsu    & Japan   & 29 899 \\ \hline
      LUMI              &  2 220 288 &  309 100 & HPE        & Finland &  6 015 \\ \hline
      Leonardo          &  1 463 616 &  174 700 & Atos       & Italy   &  5 610 \\ \hline
      Summit            &  2 414 592 &  148 600 & IBM        & USA     & 10 096 \\ \hline
      Sierra            &  1 572 480 &   94 640 & IBM/NVidia & USA     &  7 438 \\ \hline
      Sunway TaihuLight & 10 649 600 &   93 010 & NRCPC      & China   & 15 371 \\ \hline
      Perlmutter        &    761 856 &   70 870 & HPE        & USA     &  2 589 \\ \hline
      Selene            &    555 520 &   63 460 & Nvidia     & USA     &  2 646 \\ \hline
      Tianhe-2A         &  4 981 760 &   61 440 & NUDT       & China   & 18 482 \\ \hline
    \end{tabular}
    \end{center}
    \textbf{\textcolor{blue}{Remark}} : Nowadays, we look for Flops/Watt performances
  \end{frame}
  
  \section{Classification of parallel architectures}

\subsection{Shared memory}

\begin{frame}[fragile]{Shared memory architecture}
  \scriptsize

 \begin{multicols}{2}
  \begin{figure}[ht]
    \begin{tikzpicture}
      \foreach \x\n in {-2/$P_{0}$,-1/$P_{1}$,0/$P_{2}$,1/$P_{3}$} {        
        \node[draw] (P\x) at (\x,1) {\n};
        \node[anchor=center,inner sep=0pt] (M\x) at (\x,0) {};
     }
      \draw[color=red] (-2.5,0) -- (1.5,0) node[anchor=west] {\scriptsize \textcolor{red}{\sl Memory bus}};
      \foreach \x in {-2,-1,0,1} {        
        \draw[color=red] (P\x) -- (M\x);
      }
    \end{tikzpicture}
    \caption{\scriptsize Simplified scheme of shared memory parallel architecture}
  \end{figure}

  Many computing cores share the same main memory.
  
  \begin{exampleblock}{Examples}
    \begin{itemize}
    \item Recent multi-core processors
    \item Graphics cards with 3D acceleration
    \item Phones, tablets, etc.
    \end{itemize}
  \end{exampleblock}

  \begin{alertblock}{Memory access problem}
    \begin{itemize}
    \item Optimization of memory access
    \item Simultaneous read/write accesses to the same memory location
    \end{itemize}
  \end{alertblock}
  
  \end{multicols}
\end{frame}

\begin{frame}[fragile]{Memory access}

  \begin{figure}[ht]
    \begin{tikzpicture}[scale=0.8]
      \draw[color=black,->](0,0) -- (10.5,0);
      \draw[color=black,->](0,0) -- (0,6);
      \node at (5,-0.6) {\small Years};
      \foreach \a in {0,5,...,20} {
        \tikzmath{\an=1980+\a;}
        \node at (0.5*\a,-0.25) {\scriptsize \an};
      }
      \node[rotate=90] at (-1.,3) {\small Performance};
      \node at (-0.5,2) {\scriptsize 10};
      \node at (-0.5,4) {\scriptsize 100};
      \node at (-0.5,6) {\scriptsize 1000};
      \node[circle,fill=black,minimum size=2pt,inner sep=0pt] (M0) at (0.,0.) {};
      \foreach \i in {1,2,...,19} {
        \def\x{0.5*\i}
        \def\p{0.1*\i}
         \tikzmath{\im = \i-1;}
        \node[circle,fill=black,minimum size=2pt,inner sep=0pt] (M\i) at (\x,\p) {};
        \draw[color=blue] (M\im) -- (M\i);        
      }
      \node[fill=white,draw, minimum size=2pt, inner sep=1pt] (P0) at (0,0) {};
      \foreach \a/\y in {1/0.2,2/0.4,3/0.6,4/0.8,5/1.0,6/1.2,7/1.5,8/1.8,9/2.1,10/2.5,11/2.8,12/3.1,13/3.4,14/3.7,15/4.0,16/4.3,17/4.7, 18/5.0, 19/5.3, 20/5.6} {
      \tikzmath{\am=\a-1;}
      \node[fill=white,draw, minimum size=2pt, inner sep=1pt] (P\a) at (0.5*\a,\y) {};
      \draw[color=red] (P\am) -- (P\a);
      }
      \node[fill=white,draw, minimum size=2pt, inner sep=1pt](L1) at (1,5.5){};
      \node[fill=white,draw, minimum size=2pt, inner sep=1pt] (L2) at (2,5.5) {};
      \node at (1.5,5.75) {\scriptsize CPU Performance};
      \draw[color=red]  (L1) -- (L2); 

      \node[circle, fill=black, minimum size=2pt, inner sep=0pt] (L3) at (1,4.5){};
      \node[circle, fill=black, minimum size=2pt, inner sep=0pt] (L4) at (2,4.5) {};
      \node at (1.5,4.75) {\scriptsize RAM Performance};
      \draw[color=blue]  (L3) -- (L4); 

    \end{tikzpicture}
  \end{figure}
\end{frame}

\begin{frame}[fragile]{Latency memory example (Haswell architecture)}
  \scriptsize

  \begin{center}
  \begin{tabular}{|>{\columncolor{orange!25}\bfseries}c|c|c|c|}\hline
    \rowcolor{cyan!25}Level & Size & Latency (cycles) & Physical location \\ \hline\hline
    L1 Cache & 16/16 ko & 4 & In each core \\ \hline
    L2 Cache & 256   ko & 12& Shared by two cores \\ \hline
    L3 Cache & 12    Mo & 21& Shared by all cores \\ \hline
    Ram      & 32    Go & 117 & SRAM on mother board \\ \hline
    Swap     & 100+  Go & 10 000 & Hard disk or SSD \\ \hline
  \end{tabular}
\end{center}

\begin{alertblock}{Conclusion}
\begin{itemize}
    \item Memory is becoming slower in comparison to the instruction execution of the processor.
    \item This discrepancy is exacerbated in multicore architectures.
\end{itemize}
\end{alertblock}

\end{frame}

\begin{frame}[fragile]{How does RAM work ?}

    \begin{figure}[ht]
        \begin{tikzpicture}
        \foreach \i in {0,1,2,...,20}
        {
            \node at (0.2*\i,-0.75) {\fontsize{3pt}{3.6pt}\selectfont\color{blue} $E_{\i}$};
            \node at (-0.75, 0.2*\i) {\fontsize{3pt}{3.6pt}\selectfont\color{blue} $E^{\i}$};
            \draw  (0.2*\i,-0.5) -- (0.2*\i,4.5);
            \draw (-0.5,0.2*\i) -- (4.5,0.2*\i) ;
        }
        \draw[->,red] (-1.0, 1.0) -- (-0.8, 1.0);
        \draw[->,red] ( 1.4,-1.0) -- ( 1.4,-0.8);
        \node[fill=Yellow,draw,inner sep=1pt] at (1.4,1.0) {\fontsize{4pt}{4pt}\selectfont\color{red}\bf$M_{7}^{5}$};
        \node at (2,4.75) {\textcolor{DarkGreen}{Output Bus}};
    \end{tikzpicture}
\end{figure}
\end{frame}

\begin{frame}{Interleaved RAMs}
    \small
    \begin{center}
        \begin{tikzpicture}
           \node[fill=green!25!white,draw] at (-3,0) (R1) {\scriptsize RAM 1}; 
           \node[fill=red!25!white,draw] at (-1,0) (R2) {\scriptsize RAM 2}; 
           \node[fill=blue!25!white,draw] at (+1,0) (R3) {\scriptsize RAM 3}; 
           \node[fill=yellow!25!white,draw] at (+3,0) (R4) {\scriptsize RAM 4};
           \node at (4.5,0) {\scriptsize \textcolor{red}{physical rams}};
           \foreach \x in {-3.5,-2.5,-1.5,...,2.5}
           {
            \node[fill=green!25!white,draw,minimum size=0.25] at (\x,-1) {};
            \node[fill=red!25!white,draw,minimum size=0.25] at (\x+0.25,-1) {};
            \node[fill=blue!25!white,draw,minimum size=0.25] at (\x+0.5,-1) {};
            \node[fill=yellow!25!white,draw,minimum size=0.25] at (\x+0.75,-1) {};
           }
           \draw[thick, red] (-3.5,-0.5) -- (3.5,-0.5);
           \draw[thick, red] (R1) -- (-3,-0.5);
           \draw[thick, red] (R2) -- (-1,-0.5);
           \draw[thick, red] (R3) -- (+1,-0.5);
           \draw[thick, red] (R4) -- (+3,-0.5);
           \draw[thick, red, ->] (0,-0.5) -- (0,-0.875);
           \node at (4.5,-1) {\scriptsize \textcolor{blue}{logical rams}};

           \node[circle, draw] at (-2,-2) (P1) {\small Proc.};
           \node[circle, draw] at ( 0,-2) (P2) {\small Proc.};
           \node[circle, draw] at ( 2,-2) (P3) {\small Proc.};
           \draw[->] (P1) -> (-2,-1.125);
           \draw[->] (P2) -> ( 0,-1.125);
           \draw[->] (P3) -> (+2,-1.125);
        \end{tikzpicture}
    \end{center}
    \begin{block}{\small Interleaved memory}
        \begin{itemize}
            \item Multiple physical memory units interleaved by the memory bus
            \item Number of physical memory units $\equiv$ number of ways
            \item Number of contiguous bytes in a single physical memory unit $\equiv$ width of way
            \item \alert{Quadratic cost in \euro{} to build, relative to number of memory units !}
        \end{itemize}
       \end{block}
\end{frame}

\begin{frame}[fragile]{Interleaved memory access}

    \begin{block}{\small Classic memory access}
    {\scriptsize
    \begin{center}
    \begin{tikzpicture}[scale=0.5]
    \draw[->,>=latex] (0,0) -- (10,0) node[below]{cycle};
    \foreach \x in {0,1,...,9} {
      \draw (\x,1mm) -- (\x,-1mm) node[below] {$\x\strut$};
    }
    \draw[->,>=latex,blue] (0,1.5cm) node[above,black] {Request} -- (0,2mm);
    \draw[->,>=latex,red] (4,1.5cm) -- (4,2mm);
    \draw[->,>=latex,violet] (8,1.5cm) -- (8,2mm);
    
    \draw[->,>=latex,blue] (4,-4ex) -- (4,-1.5cm) node[below,black]{Data};
    \draw[->,>=latex,red] (8,-4ex) -- (8,-1.5cm);
    \end{tikzpicture}
    \end{center}
    }
    \end{block}
    \vskip-10pt
    \begin{block}{\small Four ways interleaved memory access}
    {\scriptsize
    \begin{center}
    \begin{tikzpicture}[scale=0.5]
    \draw[->,>=latex] (0,0) -- (10,0) node[below]{cycle};
    \foreach \x in {0,1,...,9} {
      \draw (\x,1mm) -- (\x,-1mm) node[below] {$\x\strut$};
    }
    \draw[->,>=latex,blue] (0,1.5cm) node[above,black] {Request} -- (0,2mm);
    \foreach \x/\col in {1/red,2/violet,3/ocre,4/blue,5/red,6/violet,7/ocre,8/blue,9/red}{
      \draw[->,>=latex,\col] (\x,1.5cm) -- (\x,2mm);
    }
    \draw[->,>=latex,blue] (4,-4ex) -- (4,-1.5cm) node[below,black] {Data};
    \foreach \x/\col in {5/red,6/violet,7/ocre,8/blue,9/red}{
      \draw[->,>=latex,\col] (\x,-4ex) -- (\x,-1.5cm);
    }
    \end{tikzpicture}
    \end{center}
    }
    \end{block}
\end{frame}
    

\begin{frame}[fragile]{Cache memory}
    \begin{block}{Consequences of grid architecture for RAMS}
        The larger the memory, the larger its grid, resulting in slower read and write access.
    \end{block}

    \begin{exampleblock}{Cache memory}
        \begin{itemize}
            \item Fast small memory unit used for storing temporary data
            \item When there are multiple accesses to the same variable \alert{in a short time}, it speeds up read or write access
            \item Cache memory managed by the CPU (although cache memory for GPUs can be managed by the programmer)
            \item \textbf{Consequence} : to optimize their program, the programmer must be aware of the strategies used by the CPU.
        \end{itemize}
    \end{exampleblock}
\end{frame}


\begin{frame}[fragile]{Cache memory}
    \begin{block}{CPU Strategy}
        \begin{itemize}
            \item \textbf{Cache Line} : store contiguous memory variables in cache (typically 64 bytes on Intel processor)
            \item \textbf{Associative memory cache} : each cache memory address mapped to fixed RAM address (using modulo)
        \end{itemize}
    \end{block}

    \begin{alertblock}{Consequences}
        \begin{itemize}
            \item advantageous to have contiguous access in memory.
            \item preferable to use data stored in the cache as soon as possible
            \item \alert{Spatial and temporal localization of data}
        \end{itemize}
    \end{alertblock}
\end{frame}



\begin{frame}[fragile]{Memory organization on multi-processor computer}
    \scriptsize
    \begin{center}
    \begin{tikzpicture}
    \node[rounded corners, drop shadow,draw,fill=blue!50!white,text height=1.5ex] (M) {RAM};
    \node[rounded corners, drop shadow,draw,fill=green!50!white, right= 6em of M.east, text height=1.5ex] (E) {Input - Output};
    \node[below=4ex of M.south] (B) {};
    \node[below=4ex of E.south] (Be) {};
    \node[below=4ex of M.south west] (B0) {};
    \foreach \x/\n in {1/B0,2/B1,3/B2,4/B3} {
      \node[right=4em of \n.east] (B\x) {};
      \node[below=2ex of B\x.south,draw,text width=3em] (C\x) {Cache};
      \node[below=1ex of C\x.south,draw,text width=3em] (P\x) {UC};
      \draw[ocre,thick] ($(C\x.north west)+(-0.1,0.1)$) rectangle ($(P\x.south east)+(0.1,-0.1)$);
      \draw[blue] (B\x.center) -- (C\x);
    }
    \node[right=4ex of B4.east] (B5) {};
    \draw[blue] (B0.west) -- (B5.east);
    \draw[blue] (M) -- (B.center);
    \draw[blue] (E) -- (Be.center);
    \node[above= 1 ex of B2.north] {Data Bus};
    \end{tikzpicture}
    \end{center}
    
    Data coherence between memory caches :
    
    {\scriptsize
    \begin{itemize}
        \item In a unique cache, the datum's value is valid, and no synchronization is needed.
        \item When a datum is shared with another memory cache, each access involves verifying if the datum has been modified by another core. The cache writes the datum as invalid when modifying its value.
        \item If the value in the cache is modified, the corresponding value in RAM is now invalid. The cache updates the value in RAM if another core reads the value.
        \item When the value is invalid in the cache, the next read of this value must access the value in RAM.
    \end{itemize}
    }
    
    \end{frame}

    \begin{frame}[fragile]{Many cores cache organization}

        \scriptsize
        \begin{center}
        \begin{tikzpicture}
        \node[rounded corners, drop shadow,draw,fill=blue!50!white,text height=1.5ex] (M) {RAM};
        \node[rounded corners, drop shadow,draw,fill=green!50!white, right= 6em of M.east, text height=1.5ex] (E) {Input - Output};
        \node[below=4ex of M.south] (B) {};
        \node[below=4ex of E.south] (Be) {};
        \node[below=4ex of M.south west] (B0) {};
        \node[right=6em of B.east] (B1) {};
        \node[right=14em of B1.east] (Br) {};
        \node[below=7ex of B1.south,text width = 16em,fill=cyan!25,draw,text centered] (L3) {L3 cache};
        \node[below=2ex of L3.south] (BL3) {};
        \node[left=3em of BL3.west,draw,text width = 4em,fill=cyan!40,text centered] (L21) {\scriptsize L2 Cache};
        \node[right=3em of BL3.east,draw,text width = 4em,fill=cyan!40, text centered] (L22) {\scriptsize L2 Cache};
        
        \node[below=1.5em of L21.south] (BL21) {};
        \node[left=0.3em of BL21.west,draw,text width = 3.5em,fill=cyan!55, text centered] (L111) {\scriptsize L1 Cache};
        \node[below=1ex of L111.south,draw,text width = 3.5em,fill=red!55, text centered] (U111) {\scriptsize UC};
        \draw[blue,thick] ($(U111.south west)+(-0.1,-0.1)$) rectangle ($(L111.north east)+(0.1,0.1)$);
        \node[right=0.3em of BL21.east,draw,text width = 3.5em,fill=cyan!55, text centered] (L112) {\scriptsize L1 Cache};
        \node[below=1ex of L112.south,draw,text width = 3.5em,fill=red!55, text centered] (U112) {\scriptsize UC};
        \draw[blue,thick] ($(U112.south west)+(-0.1,-0.1)$) rectangle ($(L112.north east)+(0.1,0.1)$);
        
        \node[below=1.5em of L22.south] (BL22) {};
        \node[left=0.3em of BL22.west,draw,text width = 3.5em,fill=cyan!55, text centered] (L121) {\scriptsize L1 Cache};
        \node[below=1ex of L121.south,draw,text width = 3.5em,fill=red!55, text centered] (U121) {\scriptsize UC};
        \draw[blue,thick] ($(U121.south west)+(-0.1,-0.1)$) rectangle ($(L121.north east)+(0.1,0.1)$);
        \node[right=0.3em of BL22.east,draw,text width = 3.5em,fill=cyan!55, text centered] (L122) {\scriptsize L1 Cache};
        \node[below=1ex of L122.south,draw,text width = 3.5em,fill=red!55, text centered] (U122) {\scriptsize UC};
        \draw[blue,thick] ($(U122.south west)+(-0.1,-0.1)$) rectangle ($(L122.north east)+(0.1,0.1)$);
        
        \draw[ocre,thick] ($(U111.south west)+(-0.2,-0.2)$) rectangle ($(L21.north -| L112.east)+(0.2,0.1)$);
        \draw[ocre,thick] ($(U121.south west)+(-0.2,-0.2)$) rectangle ($(L22.north -| L122.east)+(0.2,0.1)$);
        
        \draw[ocre!50!blue,thick] ($(U111.south west)+(-0.3,-0.3)$) rectangle ($(L3.north -| L122.east)+(0.3,0.1)$);
        
        \draw[blue] (B0.west) -- (Br.east);
        \draw[blue] (M) -- (B.center);
        \draw[blue] (E) -- (Be.center);
        \draw[blue] (B1.center) -- (L3);
        \draw[blue!75] (L3) -- (BL3.center);
        \draw[blue!75] (BL3.center) -- (L21);
        \draw[blue!75] (BL3.center) -- (L22);
        \draw[blue!50] (L21) -- (BL21.center);
        \draw[blue!50] (BL21.center) -- (L111);
        \draw[blue!50] (BL21.center) -- (L112);
        
        \draw[blue!50] (L22) -- (BL22.center);
        \draw[blue!50] (BL22.center) -- (L121);
        \draw[blue!50] (BL22.center) -- (L122);
        \draw[orange,dashed] (L21.south east) -- node[below] {\scriptsize \textcolor{black}{Bus}} (L22.south west);
        \end{tikzpicture}
        \end{center}
        
        Same issue arises with cache consistency, but there is a need for coherence of data between cache levels. The complexity increases with the number of cache levels.
        
        \end{frame}


\begin{frame}[fragile]{Tools for shared memory computation}
\small
Many tools can be used to implement multiple "threads" and synchronization in memory. The most commonly used ones are:

\begin{itemize}
    \item OpenMP: Compilation directives and a small C API (\mintinline{C++}{#pragma}).
    \item Standard Library in C++ (threads, asynchronous functions, execution policies).
    \item oneTBB (oneAPI Threading Building Block library, Intel): An open-source library from Intel.
\end{itemize}

However, the programmer must be cautious about memory conflict access:

\begin{itemize}
    \item When a thread writes to a datum, and other threads simultaneously read the same datum.
    \item When multiple threads write to the same datum.
    \item The programmer should not rely on the instruction order in the program due to out-of-order optimizations by the compiler and processor.
\end{itemize}
\end{frame}

\subsection{Distributed memory}

\begin{frame}[fragile]{Distributed memory}
    \scriptsize
    \begin{center}
    {
    \begin{tikzpicture}[scale=0.5]
    \node[draw,fill=blue!50!white, drop shadow, rounded corners] (Ram1) {RAM};
    \node[below=2ex of Ram1.south] (B1) {};
    \node[left=1em of B1.west,draw,fill=red!55] (U1) {UC};
    \node[right=1em of B1.east,draw,fill=red!55] (U2) {UC};
    \draw[blue] (Ram1) -- (B1.center);
    \draw[blue] (B1.center) -- (U1);
    \draw[blue] (B1.center) -- (U2);
    
    \node[draw,fill=blue!50!white, drop shadow, rounded corners,left=10em of Ram1.east] (Ram2) {RAM};
    \node[below=2ex of Ram2.south] (B2) {};
    \node[left=1em of B2.west,draw,fill=red!55] (U3) {UC};
    \node[right=1em of B2.east,draw,fill=red!55] (U4) {UC};
    \draw[blue] (Ram2) -- (B2.center);
    \draw[blue] (B2.center) -- (U3);
    \draw[blue] (B2.center) -- (U4);
    
    \node[draw,fill=blue!50!white, drop shadow, rounded corners,left=10em of Ram2.east] (Ram3) {RAM};
    \node[below=2ex of Ram3.south] (B3) {};
    \node[left=1em of B3.west,draw,fill=red!55] (U5) {UC};
    \node[right=1em of B3.east,draw,fill=red!55] (U6) {UC};
    \draw[blue] (Ram3) -- (B3.center);
    \draw[blue] (B3.center) -- (U5);
    \draw[blue] (B3.center) -- (U6);
    
    \node[above=2ex of Ram1.north] (R1) {};
    \node[above=2ex of Ram2.north] (R2) {};
    \node[above=2ex of Ram3.north] (R3) {};
    \node[right=1em of R1.east] (R0){};
    \node[left=1em of R3.west] (R4) {};
    \draw[thick,red] (R0.east) -- (R1.center) -- (R2.center) node[above] {Network}-- (R3.center) -- (R4.west);
    \draw[thick,red] (Ram1) -- (R1.center);
    \draw[thick,red] (Ram2) -- (R2.center);
    \draw[thick,red] (Ram3) -- (R3.center);
    \end{tikzpicture}
    }
    \end{center}
    
    \begin{itemize}
        \item Each computing unit can read/write to local RAM; the set containing the computing unit and the RAM is called the \textbf{Computing Node}.
        \item Data is exchanged between computing nodes through a specialized bus or a specific Ethernet link.
        \item On an Ethernet link, it is the responsibility of the programmer to explicitly exchange data between computing nodes.
        \item Specific efficient algorithms and libraries are required.
        \item It is possible to compute on many thousands of computing cores.
        \item The limitation is only imposed by electricity consumption (with linear cost).
    \end{itemize}    
    \end{frame}

\begin{frame}[fragile]{Distributed parallelism context}
    \small
    All libraries managing distributed parallel computation provide similar functionalities.

\begin{block}{\small Running a Distributed Parallel Application}
    \begin{itemize}
        \scriptsize
        \item The user is provided with an application to run on a specified number (\texttt{nbp}) of computing nodes (given during application execution).
        \item The computing nodes where the application is launched are defined either by default or in a file provided by the user.
        \item The default output for all processes is the terminal output from which the application was launched.
        \item A communicator (defining a set of processes) is set by default, including all launched processes (\verb@MPI_COMM_WORLD@).
        \item The application assigns a unique number to each process in a communicator (numbering from 0 to \texttt{nbp}-1).
        \item All processes terminate the program simultaneously.
    \end{itemize}
\end{block}
\end{frame}

\begin{frame}[fragile]{Managing the context in your program}
    \small
    \begin{itemize}
        \item Call the initialization of the parallel context before using other functions in the library (\verb@MPI_Init@).
        \item Obtain the number of processes contained in the communicator (\verb@MPI_Comm_size@).
        \item Retrieve the rank of the process within the communicator (\verb@MPI_Comm_rank@).
        \item After calling the last library function, invoke the termination of the parallel context to synchronize processes (\verb@MPI_Finalize@). Failure to do so may result in program crashes.
    \end{itemize}

\begin{minted}{C++}
#include <mpi.h>
int main(int nargs, char const* argv[])
{
    MPI_Comm commGlob;
    int nbp, rank;
    MPI_Init(&nargs, &argv);// Initialization of the parallel context
    MPI_Comm_dup(MPI_COMM_WORLD, &commGlob);// Copy global communicator in own communicator;
    MPI_Comm_size(commGlob, &nbp);// Get the number of processes launched by the used;
    MPI_Comm_rank(commGlob, &rank);// Get the rank of the process in the communicator commGlob.
    ...
    MPI_Finalize();// Terminates the parallel context
}
\end{minted}

\end{frame}

\begin{frame}[fragile]{Point to point data exchange}
    \scriptsize
    \begin{multicols}{2}
        \begin{block}{\small Constitution of a Data Message to Send}
            \begin{itemize}
                \item The communicator used to send the data.
                \item The memory address of the contiguous data to be sent.
                \item The number of data to send.
                \item The type of the data (integer, real, user-defined type, etc.).
                \item The rank of the destination process.
                \item A tag number to identify the message.
            \end{itemize}
        \end{block}
        
        \begin{block}{\small Constitution of a Data Message to Receive}
            \begin{itemize}
                \item The communicator used to receive the data.
                \item A memory address of a buffer to store the received data.
                \item The number of data to receive.
                \item The type of the data (integer, real, user-defined type, etc.).
                \item The rank of the sender process (can be any process).
                \item A tag number to identify the message (can be any tag if needed).
                \item Status of the message (receive status, error, sender, tag).
            \end{itemize}
        \end{block}
    \end{multicols}

\begin{minted}{C++}
    if (rank == 0) {
        double vecteur[5] = { 1., 3., 5., 7., 22. };
        MPI_Send(vecteurs, 5, MPI_DOUBLE, 1, 101, commGlob);    }
    else if (rank==1) {
        MPI_Status status;    double vecteurs[5];
        MPI_Recv(vecteurs, 5, MPI_DOUBLE, 0, 101, commGlob, &status);    }
\end{minted}

\end{frame}

\begin{frame}[fragile]{Interlocking}
    \scriptsize
    \begin{block}{Definition}
        \begin{itemize}
            \item Interlocking is a situation where many processes are waiting for each other indefinitely to complete their messages.
            \item For example, process 1 waits to receive a message from process 0, and process 0 waits to receive a message from process 1.
            \item Alternatively, process 0 sends a message to process 1, and process 1 waits for a message from process 0 but with the wrong tag.
            \item Sometimes, identifying interlocking can be challenging.
            \item \textbf{Rule of thumb}: Be careful to ensure that each send has a corresponding receive with the correct tag and expeditor.
        \end{itemize}
    \end{block}

\begin{minted}{C++}
if (rank==0)
{
    MPI_Recv(rcvbuf, count, MPI_DOUBLE, 1, 101, commGlob, &status);
    MPI_Send(sndbuf, count, MPI_DOUBLE, 1, 102, commGlob);
}
else if (rank==1)
{
    MPI_Recv(rcvbuf, count, MPI_DOUBLE, 0, 102, commGlob, &status);
    MPI_Send(sndbuf, count, MPI_DOUBLE, 0, 101, commGlob);
}
\end{minted}
\end{frame}

\begin{frame}[fragile]{Interlocking (more complicated cases)}

    \begin{minted}{C++}
    MPI_Comm_rank(comm, &myRank ) ;
    if (myRank == 0 ) 
    {
        MPI_Ssend( sendbuf1, count, MPI_INT, 2, tag, comm);
        MPI_Recv( recvbuf1, count, MPI_INT, 2, tag, comm, &status);
    } 
    else if ( myRank == 1 ) 
    {
        MPI_Ssend( sendbuf2, count, MPI_INT, 2, tag, comm);
    }
    else if ( myRank == 2 ) 
    {
        MPI_Recv( recvbuf1, count, MPI_INT, MPI_ANY_SOURCE, tag, comm,
                 &status );
        MPI_Ssend( sendbuf2, count, MPI_INT, 0, tag, comm);
        MPI_Recv( recvbuf2, count, MPI_INT, MPI_ANY_SOURCE, tag, comm,
                 &status );
    }    
    \end{minted}
    \end{frame}
    

\begin{frame}[fragile]{Blocking and non blocking message}
    \scriptsize
    \begin{block}{Definition}
        \begin{itemize}
            \item Blocking message: Waits for the complete reception of the message before returning from the function.
            \item Non-blocking message: Posts the message to send or receive and returns from the function immediately.
            \item The status of a non-blocking message is updated in a request struct (not yet sent/received, sending/receiving, or sent/received).
            \item Allows testing or waiting for the message to be completed.
        \end{itemize}
    \end{block}
    
    \begin{exampleblock}{When to Use Non-blocking Messages?}
        \begin{itemize}
            \item When one can compute using other data during message exchanges to hide the message exchange cost.
            \item To simplify algorithms and ensure no interlocking situations occur.
        \end{itemize}
    \end{exampleblock}

\end{frame}

\begin{frame}[fragile]{Example using non blocking message}
    
    \begin{minted}{C++}
        MPI_Request req;
        if (rank == 0) 
        {
            double vecteur[5] = { 1., 3., 5., 7., 22. };
            MPI_Isend(vecteurs, 5, MPI_DOUBLE, 1, 101, commGlob, &req);
            // Some compute with other data can be executed here!
            MPI_Wait(req, MPI_STATUS_IGNORE);
        }
        else if (rank==1) 
        {
            MPI_Status status;    double vecteurs[5];
                MPI_Irecv(vecteurs, 5, MPI_DOUBLE, 0, 101, commGlob, &req);
            int flag = 0;
            do {
                // Do computation while message is not received on another data
                MPI_Test(&req, &flag, &status);
            } while(flag );
        }
        \end{minted}
\end{frame}

\begin{frame}[fragile]{A scheme to avoid interlocking situations}
    \scriptsize
    \begin{block}{The Scheme for All Processes}
        \begin{enumerate}
            \item Perform receptions in non-blocking mode.
            \item Perform sends in blocking mode (or non-blocking mode if you want to overlap message cost with computing).
            \item Synchronize your receptions (waiting for completion or testing to overlap message cost with computing).
        \end{enumerate}
    \end{block}
    \begin{minted}{C++}
        MPI_Request req; MPI_Status status;
        if (rank==0)
        {
            MPI_Irecv(rcvbuf, count, MPI_DOUBLE, 1, 101, commGlob, &req);
            MPI_Send(sndbuf, count, MPI_DOUBLE, 1, 102, commGlob);
            MPI_Wait(&req, &status);
        }
        else if (rank==1)
        {
            MPI_Irecv(rcvbuf, count, MPI_DOUBLE, 0, 102, commGlob, &req);
            MPI_Send(sndbuf, count, MPI_DOUBLE, 0, 101, commGlob);
            MPI_Wait(&req, &status);
        }
        \end{minted}
\end{frame}


\begin{frame}[fragile]{Buffered or Non-buffered Messages}

    \begin{block}{Buffered Messages}
        \begin{itemize}
            \item A non-blocking send is copied into a buffer before being sent.
            \item $\Rightarrow$ \textcolor{DarkGreen}{After calling a non-blocking send, the user can modify the sent data without
                  changing the values to be sent.}
            \item This is the default behavior when sending a small message.
            \item However, copying the data into a buffer incurs memory and CPU costs.
            \item Users can call send functions that don't copy the data into a buffer.
            \item \alert{It is the responsibility of the user to avoid changing data before the completion of the message!}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[fragile]{Example of non buffered messages}
    \begin{multicols}{2}
\begin{mdframed}[backgroundcolor=green!20]
\begin{minipage}{0.45\textwidth}
\begin{minted}{c++}
std::vector<double> tab{3.,5.,7.,11.};
// Blocking non bufferized send
MPI_Ssend(tab.data(), tab.size(), 
          MPI_DOUBLE, 1, 104, commGlob);
// OK, tab sent, can modify the buffer
tab[3] = 13.;
\end{minted}
\textcolor{DarkGreen}{\small Right example}
\end{minipage}
\end{mdframed}
\begin{mdframed}[backgroundcolor=green!20]
\begin{minipage}{0.45\textwidth}
\begin{minted}{c++}
std::vector<double> tab{3.,5.,7.,11.};
// Non blocking non bufferized send
MPI_Issend(tab.data(), tab.size(), 
    MPI_DOUBLE, 1, 104, commGlob,&request);
MPI_Wait(&request, &status);
// OK, tab sent, can modify the buffer
tab[3] = 13.;
\end{minted}
\textcolor{DarkGreen}{\small Right example}
\end{minipage}
\end{mdframed}
\columnbreak
\begin{mdframed}[backgroundcolor=red!20]
\begin{minipage}{0.45\textwidth}
\begin{minted}{c++}
std::vector<double> tab{3.,5.,7.,11.};
// Non blocking non bufferized send
MPI_Issend(tab.data(), tab.size(), 
    MPI_DOUBLE, 1, 104, commGlob,&request);
// ERROR, we modify the buffer before
//        than the tab is sent !
tab[3] = 13.;
\end{minted}
\textcolor{red}{\small Wrong example}
\end{minipage}
\end{mdframed}
\end{multicols}
\end{frame}

\begin{frame}[fragile]{Collective Messages}
    \scriptsize
    \begin{exampleblock}{\scriptsize What is Collective Communication}
        \begin{itemize}
            \item Broadcast data from one process to all processes.
            \item Scatter data from one process to all processes.
            \item Gather data from all processes to one process.
            \item Reduce data (with arithmetic operation) from all processes to one/all processes.
            \item Scan data (with arithmetic operation) from all processes to all processes.
            \item All-to-all broadcast/scatter data.
        \end{itemize}
    \end{exampleblock}
    
    \begin{alertblock}{\scriptsize Why Collective Communication}
    \begin{itemize}
        \item Point-to-point communication is sufficient for many algorithms!
        \item However, for some parallel operations (broadcasting, reduction, scattering), the optimal algorithm depends on the network topology.
        \item Distributed parallel libraries provide collective communication that is optimized for various network topologies.
        \item The resulting algorithm is clearer.
    \end{itemize}
    \end{alertblock}
\end{frame}

\begin{frame}[fragile]{Distributed Parallel Rules}

    \begin{itemize}
        \item Ethernet data exchange is very slow compared to memory access: \textcolor{blue}{minimize data exchanges as much as possible}.
        \item To hide data exchange costs, it's better to compute some values during the exchange of data: \textcolor{blue}{prefer using non-blocking message exchange}.
        \item Each message has an initial cost: \textcolor{blue}{regroup data in a temporary buffer if needed}.
        \item Ensure that all processes exit the program at the same time: \textcolor{blue}{try to balance the computing load among computing nodes}.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]{Available Tools}

    \begin{itemize}
        \item Program Ethernet layers (for specialists only!).
        \item Use dedicated libraries (MPI, PVM, ...).
        \item In all cases, data exchange must be explicit, done by calling functions provided by the library.
        \item It is better to design one's software with parallelism in mind from the beginning of the project.
    \end{itemize}
\end{frame}

\end{document}
